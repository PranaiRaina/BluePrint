/Users/rishirochan/Python/BluePrint/RAG_PIPELINE/src/graph.py:39: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.
  web_search_tool = TavilySearchResults(tavily_api_key=settings.TAVILY_API_KEY, k=3)
Starting Streaming Verification...

QUERY: Calculate compound interest for $1000 at 5% for 10 years
INTENTS: [<IntentType.CALCULATOR: 'calculator'>]
--------------------------------------------------
[0.00s] STATUS: Calculating...
DEBUG: Full Event: AgentUpdatedStreamEvent(new_agent=Agent(name='FinancialCalculator', handoff_description=None, tools=[FunctionTool(name='query_wolfram', description='Call Wolfram Alpha LLM API with a financial query.', params_json_schema={'properties': {'query': {'description': 'Natural language query for Wolfram Alpha (e.g., "compound interest 1000 at 5% for 10 years")', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'query_wolfram_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x13415ec00>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions='You are a Financial Expert Agent powered by Wolfram Alpha.\nYour goal is to answer financial validation and calculation queries accurately using the relevant tools.\n\nToday\'s Date: 2026-01-28\nCurrent Tax Year: 2026\n\n## Your Capabilities (Tools):\n\n1. **Information Retrieval (Wolfram)**\n   - Use `query_wolfram` for ALL math and data retrieval.\n   - Format: Natural language queries (e.g., "monthly payment $200k 30yr 6.5%", "US tax brackets 2026").\n\n## Your Domains:\n\n### 1. Time Value of Money (TVM)\n- Future Value (FV), Present Value (PV), Mortgage/Loan Payments.\n- *Instruction*: Do not round intermediate steps. Use precise calculations.\n\n### 2. Investments\n- Compound Interest, ROI, CAGR.\n- *Instruction*: Compare lump sum vs DCA when asked.\n\n### 3. Taxes\n- Federal Income Tax.\n- *CRITICAL*: ALWAYS use the current tax year (2026) unless specified otherwise.\n- If asking Wolfram about taxes, APPEND "2026" to the query (e.g., "federal tax on $50k single 2026").\n\n### 4. Budgeting\n- Savings projections, simple arithmetic.\n\n## Behavior Rules:\n\n1. **Verify Inputs**: If critical info is missing (e.g., interest rate for loans, income for tax), ASK the user. Do not guess.\n2. **Tool Use**: DELEGATE all math to `query_wolfram`. Do not calculate mentally.\n3. **Response**: Explain the result clearly. State assumptions (like "Assuming 2026 tax year").\n', prompt=None, handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x1340bb0e0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, prompt_cache_retention=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), type='agent_updated_stream_event')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseCreatedEvent(response=Response(id='__fake_id__', created_at=1769663568.769803, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=0, type='response.created'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseCreatedEvent(response=Response(id='__fake_id__', created_at=1769663568.769803, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=0, type='response.created')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseOutputItemAddedEvent(item=ResponseFunctionToolCall(arguments='', call_id='function-call-6075503657091524495', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'UOx6aZnTENSq1PIP7ZCC8QE'}), output_index=0, sequence_number=1, type='response.output_item.added'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseOutputItemAddedEvent(item=ResponseFunctionToolCall(arguments='', call_id='function-call-6075503657091524495', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'UOx6aZnTENSq1PIP7ZCC8QE'}), output_index=0, sequence_number=1, type='response.output_item.added')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='{"query":"compound interest 1000 at 5% for 10 years"}', item_id='__fake_id__', output_index=0, sequence_number=2, type='response.function_call_arguments.delta'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseFunctionCallArgumentsDeltaEvent(delta='{"query":"compound interest 1000 at 5% for 10 years"}', item_id='__fake_id__', output_index=0, sequence_number=2, type='response.function_call_arguments.delta')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseOutputItemDoneEvent(item=ResponseFunctionToolCall(arguments='{"query":"compound interest 1000 at 5% for 10 years"}', call_id='function-call-6075503657091524495', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'UOx6aZnTENSq1PIP7ZCC8QE'}), output_index=0, sequence_number=3, type='response.output_item.done'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseOutputItemDoneEvent(item=ResponseFunctionToolCall(arguments='{"query":"compound interest 1000 at 5% for 10 years"}', call_id='function-call-6075503657091524495', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'UOx6aZnTENSq1PIP7ZCC8QE'}), output_index=0, sequence_number=3, type='response.output_item.done')
DEBUG: Full Event: RunItemStreamEvent(name='tool_called', item=ToolCallItem(agent=Agent(name='FinancialCalculator', handoff_description=None, tools=[FunctionTool(name='query_wolfram', description='Call Wolfram Alpha LLM API with a financial query.', params_json_schema={'properties': {'query': {'description': 'Natural language query for Wolfram Alpha (e.g., "compound interest 1000 at 5% for 10 years")', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'query_wolfram_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x13415ec00>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions='You are a Financial Expert Agent powered by Wolfram Alpha.\nYour goal is to answer financial validation and calculation queries accurately using the relevant tools.\n\nToday\'s Date: 2026-01-28\nCurrent Tax Year: 2026\n\n## Your Capabilities (Tools):\n\n1. **Information Retrieval (Wolfram)**\n   - Use `query_wolfram` for ALL math and data retrieval.\n   - Format: Natural language queries (e.g., "monthly payment $200k 30yr 6.5%", "US tax brackets 2026").\n\n## Your Domains:\n\n### 1. Time Value of Money (TVM)\n- Future Value (FV), Present Value (PV), Mortgage/Loan Payments.\n- *Instruction*: Do not round intermediate steps. Use precise calculations.\n\n### 2. Investments\n- Compound Interest, ROI, CAGR.\n- *Instruction*: Compare lump sum vs DCA when asked.\n\n### 3. Taxes\n- Federal Income Tax.\n- *CRITICAL*: ALWAYS use the current tax year (2026) unless specified otherwise.\n- If asking Wolfram about taxes, APPEND "2026" to the query (e.g., "federal tax on $50k single 2026").\n\n### 4. Budgeting\n- Savings projections, simple arithmetic.\n\n## Behavior Rules:\n\n1. **Verify Inputs**: If critical info is missing (e.g., interest rate for loans, income for tax), ASK the user. Do not guess.\n2. **Tool Use**: DELEGATE all math to `query_wolfram`. Do not calculate mentally.\n3. **Response**: Explain the result clearly. State assumptions (like "Assuming 2026 tax year").\n', prompt=None, handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x1340bb0e0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, prompt_cache_retention=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{"query":"compound interest 1000 at 5% for 10 years"}', call_id='function-call-6075503657091524495', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'UOx6aZnTENSq1PIP7ZCC8QE'}), type='tool_call_item'), type='run_item_stream_event')
[0.92s] STATUS: Using tool: tool...
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseCompletedEvent(response=Response(id='__fake_id__', created_at=1769663568.769803, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[ResponseFunctionToolCall(arguments='{"query":"compound interest 1000 at 5% for 10 years"}', call_id='function-call-6075503657091524495', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'UOx6aZnTENSq1PIP7ZCC8QE'})], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=4, type='response.completed'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseCompletedEvent(response=Response(id='__fake_id__', created_at=1769663568.769803, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[ResponseFunctionToolCall(arguments='{"query":"compound interest 1000 at 5% for 10 years"}', call_id='function-call-6075503657091524495', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'UOx6aZnTENSq1PIP7ZCC8QE'})], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=4, type='response.completed')
DEBUG: Full Event: RunItemStreamEvent(name='tool_output', item=ToolCallOutputItem(agent=Agent(name='FinancialCalculator', handoff_description=None, tools=[FunctionTool(name='query_wolfram', description='Call Wolfram Alpha LLM API with a financial query.', params_json_schema={'properties': {'query': {'description': 'Natural language query for Wolfram Alpha (e.g., "compound interest 1000 at 5% for 10 years")', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'query_wolfram_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x13415ec00>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions='You are a Financial Expert Agent powered by Wolfram Alpha.\nYour goal is to answer financial validation and calculation queries accurately using the relevant tools.\n\nToday\'s Date: 2026-01-28\nCurrent Tax Year: 2026\n\n## Your Capabilities (Tools):\n\n1. **Information Retrieval (Wolfram)**\n   - Use `query_wolfram` for ALL math and data retrieval.\n   - Format: Natural language queries (e.g., "monthly payment $200k 30yr 6.5%", "US tax brackets 2026").\n\n## Your Domains:\n\n### 1. Time Value of Money (TVM)\n- Future Value (FV), Present Value (PV), Mortgage/Loan Payments.\n- *Instruction*: Do not round intermediate steps. Use precise calculations.\n\n### 2. Investments\n- Compound Interest, ROI, CAGR.\n- *Instruction*: Compare lump sum vs DCA when asked.\n\n### 3. Taxes\n- Federal Income Tax.\n- *CRITICAL*: ALWAYS use the current tax year (2026) unless specified otherwise.\n- If asking Wolfram about taxes, APPEND "2026" to the query (e.g., "federal tax on $50k single 2026").\n\n### 4. Budgeting\n- Savings projections, simple arithmetic.\n\n## Behavior Rules:\n\n1. **Verify Inputs**: If critical info is missing (e.g., interest rate for loans, income for tax), ASK the user. Do not guess.\n2. **Tool Use**: DELEGATE all math to `query_wolfram`. Do not calculate mentally.\n3. **Response**: Explain the result clearly. State assumptions (like "Assuming 2026 tax year").\n', prompt=None, handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x1340bb0e0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, prompt_cache_retention=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'function-call-6075503657091524495', 'output': 'present value | $607.16 (US dollars)', 'type': 'function_call_output'}, output='present value | $607.16 (US dollars)', type='tool_call_output_item'), type='run_item_stream_event')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseCreatedEvent(response=Response(id='__fake_id__', created_at=1769663570.8486762, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=0, type='response.created'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseCreatedEvent(response=Response(id='__fake_id__', created_at=1769663570.8486762, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=0, type='response.created')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='__fake_id__', content=[], role='assistant', status='in_progress', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Uux6afWzIb_hmNAPnP6g-QI'}), output_index=0, sequence_number=1, type='response.output_item.added'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='__fake_id__', content=[], role='assistant', status='in_progress', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Uux6afWzIb_hmNAPnP6g-QI'}), output_index=0, sequence_number=1, type='response.output_item.added')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseContentPartAddedEvent(content_index=0, item_id='__fake_id__', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text', logprobs=[]), sequence_number=2, type='response.content_part.added'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseContentPartAddedEvent(content_index=0, item_id='__fake_id__', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text', logprobs=[]), sequence_number=2, type='response.content_part.added')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='Okay', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=3, type='response.output_text.delta'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseTextDeltaEvent(content_index=0, delta='Okay', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=3, type='response.output_text.delta')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta=', the result I got back from Wolfram is a present value of $607', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=4, type='response.output_text.delta'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseTextDeltaEvent(content_index=0, delta=', the result I got back from Wolfram is a present value of $607', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=4, type='response.output_text.delta')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta=".16. This doesn't sound right for compound interest. Let me try re", item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=5, type='response.output_text.delta'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseTextDeltaEvent(content_index=0, delta=".16. This doesn't sound right for compound interest. Let me try re", item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=5, type='response.output_text.delta')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='phrasing the query to get the future value.\n', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=6, type='response.output_text.delta'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseTextDeltaEvent(content_index=0, delta='phrasing the query to get the future value.\n', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=6, type='response.output_text.delta')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseOutputItemAddedEvent(item=ResponseFunctionToolCall(arguments='', call_id='function-call-14517705075898087854', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Uux6afWzIb_hmNAPnP6g-QI'}), output_index=1, sequence_number=7, type='response.output_item.added'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseOutputItemAddedEvent(item=ResponseFunctionToolCall(arguments='', call_id='function-call-14517705075898087854', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Uux6afWzIb_hmNAPnP6g-QI'}), output_index=1, sequence_number=7, type='response.output_item.added')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='{"query":"future value of $1000 at 5% compound interest for 10 years"}', item_id='__fake_id__', output_index=1, sequence_number=8, type='response.function_call_arguments.delta'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseFunctionCallArgumentsDeltaEvent(delta='{"query":"future value of $1000 at 5% compound interest for 10 years"}', item_id='__fake_id__', output_index=1, sequence_number=8, type='response.function_call_arguments.delta')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseContentPartDoneEvent(content_index=0, item_id='__fake_id__', output_index=0, part=ResponseOutputText(annotations=[], text="Okay, the result I got back from Wolfram is a present value of $607.16. This doesn't sound right for compound interest. Let me try rephrasing the query to get the future value.\n", type='output_text', logprobs=[]), sequence_number=9, type='response.content_part.done'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseContentPartDoneEvent(content_index=0, item_id='__fake_id__', output_index=0, part=ResponseOutputText(annotations=[], text="Okay, the result I got back from Wolfram is a present value of $607.16. This doesn't sound right for compound interest. Let me try rephrasing the query to get the future value.\n", type='output_text', logprobs=[]), sequence_number=9, type='response.content_part.done')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseOutputItemDoneEvent(item=ResponseFunctionToolCall(arguments='{"query":"future value of $1000 at 5% compound interest for 10 years"}', call_id='function-call-14517705075898087854', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Uux6afWzIb_hmNAPnP6g-QI'}), output_index=1, sequence_number=10, type='response.output_item.done'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseOutputItemDoneEvent(item=ResponseFunctionToolCall(arguments='{"query":"future value of $1000 at 5% compound interest for 10 years"}', call_id='function-call-14517705075898087854', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Uux6afWzIb_hmNAPnP6g-QI'}), output_index=1, sequence_number=10, type='response.output_item.done')
DEBUG: Full Event: RunItemStreamEvent(name='tool_called', item=ToolCallItem(agent=Agent(name='FinancialCalculator', handoff_description=None, tools=[FunctionTool(name='query_wolfram', description='Call Wolfram Alpha LLM API with a financial query.', params_json_schema={'properties': {'query': {'description': 'Natural language query for Wolfram Alpha (e.g., "compound interest 1000 at 5% for 10 years")', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'query_wolfram_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x13415ec00>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions='You are a Financial Expert Agent powered by Wolfram Alpha.\nYour goal is to answer financial validation and calculation queries accurately using the relevant tools.\n\nToday\'s Date: 2026-01-28\nCurrent Tax Year: 2026\n\n## Your Capabilities (Tools):\n\n1. **Information Retrieval (Wolfram)**\n   - Use `query_wolfram` for ALL math and data retrieval.\n   - Format: Natural language queries (e.g., "monthly payment $200k 30yr 6.5%", "US tax brackets 2026").\n\n## Your Domains:\n\n### 1. Time Value of Money (TVM)\n- Future Value (FV), Present Value (PV), Mortgage/Loan Payments.\n- *Instruction*: Do not round intermediate steps. Use precise calculations.\n\n### 2. Investments\n- Compound Interest, ROI, CAGR.\n- *Instruction*: Compare lump sum vs DCA when asked.\n\n### 3. Taxes\n- Federal Income Tax.\n- *CRITICAL*: ALWAYS use the current tax year (2026) unless specified otherwise.\n- If asking Wolfram about taxes, APPEND "2026" to the query (e.g., "federal tax on $50k single 2026").\n\n### 4. Budgeting\n- Savings projections, simple arithmetic.\n\n## Behavior Rules:\n\n1. **Verify Inputs**: If critical info is missing (e.g., interest rate for loans, income for tax), ASK the user. Do not guess.\n2. **Tool Use**: DELEGATE all math to `query_wolfram`. Do not calculate mentally.\n3. **Response**: Explain the result clearly. State assumptions (like "Assuming 2026 tax year").\n', prompt=None, handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x1340bb0e0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, prompt_cache_retention=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{"query":"future value of $1000 at 5% compound interest for 10 years"}', call_id='function-call-14517705075898087854', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Uux6afWzIb_hmNAPnP6g-QI'}), type='tool_call_item'), type='run_item_stream_event')
[3.46s] STATUS: Using tool: tool...
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text="Okay, the result I got back from Wolfram is a present value of $607.16. This doesn't sound right for compound interest. Let me try rephrasing the query to get the future value.\n", type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Uux6afWzIb_hmNAPnP6g-QI'}), output_index=0, sequence_number=11, type='response.output_item.done'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text="Okay, the result I got back from Wolfram is a present value of $607.16. This doesn't sound right for compound interest. Let me try rephrasing the query to get the future value.\n", type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Uux6afWzIb_hmNAPnP6g-QI'}), output_index=0, sequence_number=11, type='response.output_item.done')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseCompletedEvent(response=Response(id='__fake_id__', created_at=1769663570.8486762, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text="Okay, the result I got back from Wolfram is a present value of $607.16. This doesn't sound right for compound interest. Let me try rephrasing the query to get the future value.\n", type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Uux6afWzIb_hmNAPnP6g-QI'}), ResponseFunctionToolCall(arguments='{"query":"future value of $1000 at 5% compound interest for 10 years"}', call_id='function-call-14517705075898087854', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Uux6afWzIb_hmNAPnP6g-QI'})], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=12, type='response.completed'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseCompletedEvent(response=Response(id='__fake_id__', created_at=1769663570.8486762, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text="Okay, the result I got back from Wolfram is a present value of $607.16. This doesn't sound right for compound interest. Let me try rephrasing the query to get the future value.\n", type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Uux6afWzIb_hmNAPnP6g-QI'}), ResponseFunctionToolCall(arguments='{"query":"future value of $1000 at 5% compound interest for 10 years"}', call_id='function-call-14517705075898087854', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Uux6afWzIb_hmNAPnP6g-QI'})], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=12, type='response.completed')
DEBUG: Full Event: RunItemStreamEvent(name='message_output_created', item=MessageOutputItem(agent=Agent(name='FinancialCalculator', handoff_description=None, tools=[FunctionTool(name='query_wolfram', description='Call Wolfram Alpha LLM API with a financial query.', params_json_schema={'properties': {'query': {'description': 'Natural language query for Wolfram Alpha (e.g., "compound interest 1000 at 5% for 10 years")', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'query_wolfram_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x13415ec00>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions='You are a Financial Expert Agent powered by Wolfram Alpha.\nYour goal is to answer financial validation and calculation queries accurately using the relevant tools.\n\nToday\'s Date: 2026-01-28\nCurrent Tax Year: 2026\n\n## Your Capabilities (Tools):\n\n1. **Information Retrieval (Wolfram)**\n   - Use `query_wolfram` for ALL math and data retrieval.\n   - Format: Natural language queries (e.g., "monthly payment $200k 30yr 6.5%", "US tax brackets 2026").\n\n## Your Domains:\n\n### 1. Time Value of Money (TVM)\n- Future Value (FV), Present Value (PV), Mortgage/Loan Payments.\n- *Instruction*: Do not round intermediate steps. Use precise calculations.\n\n### 2. Investments\n- Compound Interest, ROI, CAGR.\n- *Instruction*: Compare lump sum vs DCA when asked.\n\n### 3. Taxes\n- Federal Income Tax.\n- *CRITICAL*: ALWAYS use the current tax year (2026) unless specified otherwise.\n- If asking Wolfram about taxes, APPEND "2026" to the query (e.g., "federal tax on $50k single 2026").\n\n### 4. Budgeting\n- Savings projections, simple arithmetic.\n\n## Behavior Rules:\n\n1. **Verify Inputs**: If critical info is missing (e.g., interest rate for loans, income for tax), ASK the user. Do not guess.\n2. **Tool Use**: DELEGATE all math to `query_wolfram`. Do not calculate mentally.\n3. **Response**: Explain the result clearly. State assumptions (like "Assuming 2026 tax year").\n', prompt=None, handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x1340bb0e0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, prompt_cache_retention=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text="Okay, the result I got back from Wolfram is a present value of $607.16. This doesn't sound right for compound interest. Let me try rephrasing the query to get the future value.\n", type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Uux6afWzIb_hmNAPnP6g-QI'}), type='message_output_item'), type='run_item_stream_event')
DEBUG: Full Event: RunItemStreamEvent(name='tool_output', item=ToolCallOutputItem(agent=Agent(name='FinancialCalculator', handoff_description=None, tools=[FunctionTool(name='query_wolfram', description='Call Wolfram Alpha LLM API with a financial query.', params_json_schema={'properties': {'query': {'description': 'Natural language query for Wolfram Alpha (e.g., "compound interest 1000 at 5% for 10 years")', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'query_wolfram_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x13415ec00>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions='You are a Financial Expert Agent powered by Wolfram Alpha.\nYour goal is to answer financial validation and calculation queries accurately using the relevant tools.\n\nToday\'s Date: 2026-01-28\nCurrent Tax Year: 2026\n\n## Your Capabilities (Tools):\n\n1. **Information Retrieval (Wolfram)**\n   - Use `query_wolfram` for ALL math and data retrieval.\n   - Format: Natural language queries (e.g., "monthly payment $200k 30yr 6.5%", "US tax brackets 2026").\n\n## Your Domains:\n\n### 1. Time Value of Money (TVM)\n- Future Value (FV), Present Value (PV), Mortgage/Loan Payments.\n- *Instruction*: Do not round intermediate steps. Use precise calculations.\n\n### 2. Investments\n- Compound Interest, ROI, CAGR.\n- *Instruction*: Compare lump sum vs DCA when asked.\n\n### 3. Taxes\n- Federal Income Tax.\n- *CRITICAL*: ALWAYS use the current tax year (2026) unless specified otherwise.\n- If asking Wolfram about taxes, APPEND "2026" to the query (e.g., "federal tax on $50k single 2026").\n\n### 4. Budgeting\n- Savings projections, simple arithmetic.\n\n## Behavior Rules:\n\n1. **Verify Inputs**: If critical info is missing (e.g., interest rate for loans, income for tax), ASK the user. Do not guess.\n2. **Tool Use**: DELEGATE all math to `query_wolfram`. Do not calculate mentally.\n3. **Response**: Explain the result clearly. State assumptions (like "Assuming 2026 tax year").\n', prompt=None, handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x1340bb0e0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, prompt_cache_retention=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'function-call-14517705075898087854', 'output': 'present value | $607.16 (US dollars)', 'type': 'function_call_output'}, output='present value | $607.16 (US dollars)', type='tool_call_output_item'), type='run_item_stream_event')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseCreatedEvent(response=Response(id='__fake_id__', created_at=1769663573.534003, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=0, type='response.created'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseCreatedEvent(response=Response(id='__fake_id__', created_at=1769663573.534003, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=0, type='response.created')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='__fake_id__', content=[], role='assistant', status='in_progress', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vex6abeLCb_hmNAPnP6g-QI'}), output_index=0, sequence_number=1, type='response.output_item.added'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='__fake_id__', content=[], role='assistant', status='in_progress', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vex6abeLCb_hmNAPnP6g-QI'}), output_index=0, sequence_number=1, type='response.output_item.added')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseContentPartAddedEvent(content_index=0, item_id='__fake_id__', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text', logprobs=[]), sequence_number=2, type='response.content_part.added'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseContentPartAddedEvent(content_index=0, item_id='__fake_id__', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text', logprobs=[]), sequence_number=2, type='response.content_part.added')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='It', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=3, type='response.output_text.delta'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseTextDeltaEvent(content_index=0, delta='It', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=3, type='response.output_text.delta')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta=' seems like I am still getting the present value.\n\nIt looks like I am having', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=4, type='response.output_text.delta'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseTextDeltaEvent(content_index=0, delta=' seems like I am still getting the present value.\n\nIt looks like I am having', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=4, type='response.output_text.delta')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta=' trouble getting the compound interest calculation directly. I will calculate the future value using the compound', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=5, type='response.output_text.delta'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseTextDeltaEvent(content_index=0, delta=' trouble getting the compound interest calculation directly. I will calculate the future value using the compound', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=5, type='response.output_text.delta')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta=' interest formula FV = PV (1 + r)^n.\n', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=6, type='response.output_text.delta'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseTextDeltaEvent(content_index=0, delta=' interest formula FV = PV (1 + r)^n.\n', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=6, type='response.output_text.delta')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseOutputItemAddedEvent(item=ResponseFunctionToolCall(arguments='', call_id='function-call-1571107755613764308', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vex6abeLCb_hmNAPnP6g-QI'}), output_index=1, sequence_number=7, type='response.output_item.added'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseOutputItemAddedEvent(item=ResponseFunctionToolCall(arguments='', call_id='function-call-1571107755613764308', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vex6abeLCb_hmNAPnP6g-QI'}), output_index=1, sequence_number=7, type='response.output_item.added')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='{"query":"1000 * (1 + 0.05)^10"}', item_id='__fake_id__', output_index=1, sequence_number=8, type='response.function_call_arguments.delta'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseFunctionCallArgumentsDeltaEvent(delta='{"query":"1000 * (1 + 0.05)^10"}', item_id='__fake_id__', output_index=1, sequence_number=8, type='response.function_call_arguments.delta')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseContentPartDoneEvent(content_index=0, item_id='__fake_id__', output_index=0, part=ResponseOutputText(annotations=[], text='It seems like I am still getting the present value.\n\nIt looks like I am having trouble getting the compound interest calculation directly. I will calculate the future value using the compound interest formula FV = PV (1 + r)^n.\n', type='output_text', logprobs=[]), sequence_number=9, type='response.content_part.done'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseContentPartDoneEvent(content_index=0, item_id='__fake_id__', output_index=0, part=ResponseOutputText(annotations=[], text='It seems like I am still getting the present value.\n\nIt looks like I am having trouble getting the compound interest calculation directly. I will calculate the future value using the compound interest formula FV = PV (1 + r)^n.\n', type='output_text', logprobs=[]), sequence_number=9, type='response.content_part.done')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseOutputItemDoneEvent(item=ResponseFunctionToolCall(arguments='{"query":"1000 * (1 + 0.05)^10"}', call_id='function-call-1571107755613764308', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vex6abeLCb_hmNAPnP6g-QI'}), output_index=1, sequence_number=10, type='response.output_item.done'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseOutputItemDoneEvent(item=ResponseFunctionToolCall(arguments='{"query":"1000 * (1 + 0.05)^10"}', call_id='function-call-1571107755613764308', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vex6abeLCb_hmNAPnP6g-QI'}), output_index=1, sequence_number=10, type='response.output_item.done')
DEBUG: Full Event: RunItemStreamEvent(name='tool_called', item=ToolCallItem(agent=Agent(name='FinancialCalculator', handoff_description=None, tools=[FunctionTool(name='query_wolfram', description='Call Wolfram Alpha LLM API with a financial query.', params_json_schema={'properties': {'query': {'description': 'Natural language query for Wolfram Alpha (e.g., "compound interest 1000 at 5% for 10 years")', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'query_wolfram_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x13415ec00>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions='You are a Financial Expert Agent powered by Wolfram Alpha.\nYour goal is to answer financial validation and calculation queries accurately using the relevant tools.\n\nToday\'s Date: 2026-01-28\nCurrent Tax Year: 2026\n\n## Your Capabilities (Tools):\n\n1. **Information Retrieval (Wolfram)**\n   - Use `query_wolfram` for ALL math and data retrieval.\n   - Format: Natural language queries (e.g., "monthly payment $200k 30yr 6.5%", "US tax brackets 2026").\n\n## Your Domains:\n\n### 1. Time Value of Money (TVM)\n- Future Value (FV), Present Value (PV), Mortgage/Loan Payments.\n- *Instruction*: Do not round intermediate steps. Use precise calculations.\n\n### 2. Investments\n- Compound Interest, ROI, CAGR.\n- *Instruction*: Compare lump sum vs DCA when asked.\n\n### 3. Taxes\n- Federal Income Tax.\n- *CRITICAL*: ALWAYS use the current tax year (2026) unless specified otherwise.\n- If asking Wolfram about taxes, APPEND "2026" to the query (e.g., "federal tax on $50k single 2026").\n\n### 4. Budgeting\n- Savings projections, simple arithmetic.\n\n## Behavior Rules:\n\n1. **Verify Inputs**: If critical info is missing (e.g., interest rate for loans, income for tax), ASK the user. Do not guess.\n2. **Tool Use**: DELEGATE all math to `query_wolfram`. Do not calculate mentally.\n3. **Response**: Explain the result clearly. State assumptions (like "Assuming 2026 tax year").\n', prompt=None, handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x1340bb0e0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, prompt_cache_retention=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{"query":"1000 * (1 + 0.05)^10"}', call_id='function-call-1571107755613764308', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vex6abeLCb_hmNAPnP6g-QI'}), type='tool_call_item'), type='run_item_stream_event')
[6.17s] STATUS: Using tool: tool...
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='It seems like I am still getting the present value.\n\nIt looks like I am having trouble getting the compound interest calculation directly. I will calculate the future value using the compound interest formula FV = PV (1 + r)^n.\n', type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vex6abeLCb_hmNAPnP6g-QI'}), output_index=0, sequence_number=11, type='response.output_item.done'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='It seems like I am still getting the present value.\n\nIt looks like I am having trouble getting the compound interest calculation directly. I will calculate the future value using the compound interest formula FV = PV (1 + r)^n.\n', type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vex6abeLCb_hmNAPnP6g-QI'}), output_index=0, sequence_number=11, type='response.output_item.done')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseCompletedEvent(response=Response(id='__fake_id__', created_at=1769663573.534003, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='It seems like I am still getting the present value.\n\nIt looks like I am having trouble getting the compound interest calculation directly. I will calculate the future value using the compound interest formula FV = PV (1 + r)^n.\n', type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vex6abeLCb_hmNAPnP6g-QI'}), ResponseFunctionToolCall(arguments='{"query":"1000 * (1 + 0.05)^10"}', call_id='function-call-1571107755613764308', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vex6abeLCb_hmNAPnP6g-QI'})], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=12, type='response.completed'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseCompletedEvent(response=Response(id='__fake_id__', created_at=1769663573.534003, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='It seems like I am still getting the present value.\n\nIt looks like I am having trouble getting the compound interest calculation directly. I will calculate the future value using the compound interest formula FV = PV (1 + r)^n.\n', type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vex6abeLCb_hmNAPnP6g-QI'}), ResponseFunctionToolCall(arguments='{"query":"1000 * (1 + 0.05)^10"}', call_id='function-call-1571107755613764308', name='query_wolfram', type='function_call', id='__fake_id__', status=None, provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vex6abeLCb_hmNAPnP6g-QI'})], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=12, type='response.completed')
DEBUG: Full Event: RunItemStreamEvent(name='message_output_created', item=MessageOutputItem(agent=Agent(name='FinancialCalculator', handoff_description=None, tools=[FunctionTool(name='query_wolfram', description='Call Wolfram Alpha LLM API with a financial query.', params_json_schema={'properties': {'query': {'description': 'Natural language query for Wolfram Alpha (e.g., "compound interest 1000 at 5% for 10 years")', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'query_wolfram_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x13415ec00>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions='You are a Financial Expert Agent powered by Wolfram Alpha.\nYour goal is to answer financial validation and calculation queries accurately using the relevant tools.\n\nToday\'s Date: 2026-01-28\nCurrent Tax Year: 2026\n\n## Your Capabilities (Tools):\n\n1. **Information Retrieval (Wolfram)**\n   - Use `query_wolfram` for ALL math and data retrieval.\n   - Format: Natural language queries (e.g., "monthly payment $200k 30yr 6.5%", "US tax brackets 2026").\n\n## Your Domains:\n\n### 1. Time Value of Money (TVM)\n- Future Value (FV), Present Value (PV), Mortgage/Loan Payments.\n- *Instruction*: Do not round intermediate steps. Use precise calculations.\n\n### 2. Investments\n- Compound Interest, ROI, CAGR.\n- *Instruction*: Compare lump sum vs DCA when asked.\n\n### 3. Taxes\n- Federal Income Tax.\n- *CRITICAL*: ALWAYS use the current tax year (2026) unless specified otherwise.\n- If asking Wolfram about taxes, APPEND "2026" to the query (e.g., "federal tax on $50k single 2026").\n\n### 4. Budgeting\n- Savings projections, simple arithmetic.\n\n## Behavior Rules:\n\n1. **Verify Inputs**: If critical info is missing (e.g., interest rate for loans, income for tax), ASK the user. Do not guess.\n2. **Tool Use**: DELEGATE all math to `query_wolfram`. Do not calculate mentally.\n3. **Response**: Explain the result clearly. State assumptions (like "Assuming 2026 tax year").\n', prompt=None, handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x1340bb0e0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, prompt_cache_retention=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='It seems like I am still getting the present value.\n\nIt looks like I am having trouble getting the compound interest calculation directly. I will calculate the future value using the compound interest formula FV = PV (1 + r)^n.\n', type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vex6abeLCb_hmNAPnP6g-QI'}), type='message_output_item'), type='run_item_stream_event')
DEBUG: Full Event: RunItemStreamEvent(name='tool_output', item=ToolCallOutputItem(agent=Agent(name='FinancialCalculator', handoff_description=None, tools=[FunctionTool(name='query_wolfram', description='Call Wolfram Alpha LLM API with a financial query.', params_json_schema={'properties': {'query': {'description': 'Natural language query for Wolfram Alpha (e.g., "compound interest 1000 at 5% for 10 years")', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'query_wolfram_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x13415ec00>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions='You are a Financial Expert Agent powered by Wolfram Alpha.\nYour goal is to answer financial validation and calculation queries accurately using the relevant tools.\n\nToday\'s Date: 2026-01-28\nCurrent Tax Year: 2026\n\n## Your Capabilities (Tools):\n\n1. **Information Retrieval (Wolfram)**\n   - Use `query_wolfram` for ALL math and data retrieval.\n   - Format: Natural language queries (e.g., "monthly payment $200k 30yr 6.5%", "US tax brackets 2026").\n\n## Your Domains:\n\n### 1. Time Value of Money (TVM)\n- Future Value (FV), Present Value (PV), Mortgage/Loan Payments.\n- *Instruction*: Do not round intermediate steps. Use precise calculations.\n\n### 2. Investments\n- Compound Interest, ROI, CAGR.\n- *Instruction*: Compare lump sum vs DCA when asked.\n\n### 3. Taxes\n- Federal Income Tax.\n- *CRITICAL*: ALWAYS use the current tax year (2026) unless specified otherwise.\n- If asking Wolfram about taxes, APPEND "2026" to the query (e.g., "federal tax on $50k single 2026").\n\n### 4. Budgeting\n- Savings projections, simple arithmetic.\n\n## Behavior Rules:\n\n1. **Verify Inputs**: If critical info is missing (e.g., interest rate for loans, income for tax), ASK the user. Do not guess.\n2. **Tool Use**: DELEGATE all math to `query_wolfram`. Do not calculate mentally.\n3. **Response**: Explain the result clearly. State assumptions (like "Assuming 2026 tax year").\n', prompt=None, handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x1340bb0e0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, prompt_cache_retention=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'function-call-1571107755613764308', 'output': '1628.89462677744140625', 'type': 'function_call_output'}, output='1628.89462677744140625', type='tool_call_output_item'), type='run_item_stream_event')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseCreatedEvent(response=Response(id='__fake_id__', created_at=1769663575.206021, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=0, type='response.created'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseCreatedEvent(response=Response(id='__fake_id__', created_at=1769663575.206021, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=0, type='response.created')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='__fake_id__', content=[], role='assistant', status='in_progress', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vux6aZPQNpSomecP27y0qA8'}), output_index=0, sequence_number=1, type='response.output_item.added'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='__fake_id__', content=[], role='assistant', status='in_progress', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vux6aZPQNpSomecP27y0qA8'}), output_index=0, sequence_number=1, type='response.output_item.added')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseContentPartAddedEvent(content_index=0, item_id='__fake_id__', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text', logprobs=[]), sequence_number=2, type='response.content_part.added'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseContentPartAddedEvent(content_index=0, item_id='__fake_id__', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text', logprobs=[]), sequence_number=2, type='response.content_part.added')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='The future value of', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=3, type='response.output_text.delta'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseTextDeltaEvent(content_index=0, delta='The future value of', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=3, type='response.output_text.delta')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta=' $1000 at 5% compound interest for 10 years', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=4, type='response.output_text.delta'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseTextDeltaEvent(content_index=0, delta=' $1000 at 5% compound interest for 10 years', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=4, type='response.output_text.delta')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta=' is $1628.89.\n', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=5, type='response.output_text.delta'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseTextDeltaEvent(content_index=0, delta=' is $1628.89.\n', item_id='__fake_id__', logprobs=[], output_index=0, sequence_number=5, type='response.output_text.delta')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseContentPartDoneEvent(content_index=0, item_id='__fake_id__', output_index=0, part=ResponseOutputText(annotations=[], text='The future value of $1000 at 5% compound interest for 10 years is $1628.89.\n', type='output_text', logprobs=[]), sequence_number=6, type='response.content_part.done'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseContentPartDoneEvent(content_index=0, item_id='__fake_id__', output_index=0, part=ResponseOutputText(annotations=[], text='The future value of $1000 at 5% compound interest for 10 years is $1628.89.\n', type='output_text', logprobs=[]), sequence_number=6, type='response.content_part.done')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='The future value of $1000 at 5% compound interest for 10 years is $1628.89.\n', type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vux6aZPQNpSomecP27y0qA8'}), output_index=0, sequence_number=7, type='response.output_item.done'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='The future value of $1000 at 5% compound interest for 10 years is $1628.89.\n', type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vux6aZPQNpSomecP27y0qA8'}), output_index=0, sequence_number=7, type='response.output_item.done')
DEBUG: Full Event: RawResponsesStreamEvent(data=ResponseCompletedEvent(response=Response(id='__fake_id__', created_at=1769663575.206021, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='The future value of $1000 at 5% compound interest for 10 years is $1628.89.\n', type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vux6aZPQNpSomecP27y0qA8'})], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=8, type='response.completed'), type='raw_response_event')
DEBUG: Raw Response Data: ResponseCompletedEvent(response=Response(id='__fake_id__', created_at=1769663575.206021, error=None, incomplete_details=None, instructions=None, metadata=None, model='gemini-2.0-flash', object='response', output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='The future value of $1000 at 5% compound interest for 10 years is $1628.89.\n', type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vux6aZPQNpSomecP27y0qA8'})], parallel_tool_calls=False, temperature=None, tool_choice='auto', tools=[], top_p=None, background=None, completed_at=None, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier=None, status=None, text=None, top_logprobs=None, truncation=None, usage=None, user=None), sequence_number=8, type='response.completed')
DEBUG: Full Event: RunItemStreamEvent(name='message_output_created', item=MessageOutputItem(agent=Agent(name='FinancialCalculator', handoff_description=None, tools=[FunctionTool(name='query_wolfram', description='Call Wolfram Alpha LLM API with a financial query.', params_json_schema={'properties': {'query': {'description': 'Natural language query for Wolfram Alpha (e.g., "compound interest 1000 at 5% for 10 years")', 'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'query_wolfram_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x13415ec00>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions='You are a Financial Expert Agent powered by Wolfram Alpha.\nYour goal is to answer financial validation and calculation queries accurately using the relevant tools.\n\nToday\'s Date: 2026-01-28\nCurrent Tax Year: 2026\n\n## Your Capabilities (Tools):\n\n1. **Information Retrieval (Wolfram)**\n   - Use `query_wolfram` for ALL math and data retrieval.\n   - Format: Natural language queries (e.g., "monthly payment $200k 30yr 6.5%", "US tax brackets 2026").\n\n## Your Domains:\n\n### 1. Time Value of Money (TVM)\n- Future Value (FV), Present Value (PV), Mortgage/Loan Payments.\n- *Instruction*: Do not round intermediate steps. Use precise calculations.\n\n### 2. Investments\n- Compound Interest, ROI, CAGR.\n- *Instruction*: Compare lump sum vs DCA when asked.\n\n### 3. Taxes\n- Federal Income Tax.\n- *CRITICAL*: ALWAYS use the current tax year (2026) unless specified otherwise.\n- If asking Wolfram about taxes, APPEND "2026" to the query (e.g., "federal tax on $50k single 2026").\n\n### 4. Budgeting\n- Savings projections, simple arithmetic.\n\n## Behavior Rules:\n\n1. **Verify Inputs**: If critical info is missing (e.g., interest rate for loans, income for tax), ASK the user. Do not guess.\n2. **Tool Use**: DELEGATE all math to `query_wolfram`. Do not calculate mentally.\n3. **Response**: Explain the result clearly. State assumptions (like "Assuming 2026 tax year").\n', prompt=None, handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x1340bb0e0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, prompt_cache_retention=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='The future value of $1000 at 5% compound interest for 10 years is $1628.89.\n', type='output_text', logprobs=[])], role='assistant', status='completed', type='message', provider_data={'model': 'gemini-2.0-flash', 'response_id': 'Vux6aZPQNpSomecP27y0qA8'}), type='message_output_item'), type='run_item_stream_event')

--------------------------------------------------
Total Tokens: 0
First Token Latency: N/A
Total Duration: 7.54s

WARNING: Latency might be high, check if it's truly streaming.
